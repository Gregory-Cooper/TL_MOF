{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.9]\n",
      " [ 3.7]\n",
      " [11.9]\n",
      " ...\n",
      " [ 6. ]\n",
      " [ 3.7]\n",
      " [ 7.6]]\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12660/2046130720.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sherpa\n",
    "\n",
    "# help function\n",
    "from transfer_learning import NeuralNet_sherpa_optimize\n",
    "from dataset_loader import (\n",
    "    data_loader,\n",
    "    all_filter,\n",
    "    get_descriptors,\n",
    "    one_filter,\n",
    "    data_scaler,\n",
    ")\n",
    "\n",
    "# modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from Statistics_helper import stratified_cluster_sample\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "parameters = [\n",
    "    sherpa.Continuous(name=\"lr\", range=[0.0002, 0.1], scale=\"log\"),\n",
    "    # sherpa.Discrete(name='Epoch', range=[10,100]),\n",
    "    sherpa.Discrete(name=\"H_l1\", range=[10, 300]),\n",
    "    sherpa.Choice(\n",
    "        name=\"activate\",\n",
    "        range=[\"nn.Hardswish\", \"nn.PReLU\", \"nn.ReLU\", \"nn.Sigmoid\", \"nn.LeakyReLU\"],\n",
    "    ),\n",
    "]\n",
    "algorithm = sherpa.algorithms.RandomSearch(max_num_trials=10)\n",
    "study = sherpa.Study(\n",
    "    parameters=parameters,\n",
    "    algorithm=algorithm,\n",
    "    lower_is_better=False,\n",
    "    disable_dashboard=True,\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_path = os.getcwd()\n",
    "file_name = \"data/CrystGrowthDesign_SI.csv\"\n",
    "\n",
    "\"\"\"\n",
    "Data description.\n",
    "\n",
    "    Descriptors:\n",
    "        'void fraction', 'Vol. S.A.', 'Grav. S.A.', 'Pore diameter Limiting', 'Pore diameter Largest'\n",
    "    Source task:\n",
    "        'H2@100 bar/243K (wt%)'\n",
    "    Target tasks:\n",
    "        'H2@100 bar/130K (wt%)' 'CH4@100 bar/298 K (mg/g)' '5 bar Xe mol/kg' '5 bar Kr mol/kg'\n",
    "\"\"\"\n",
    "\n",
    "descriptor_columns = [\n",
    "    \"void fraction\",\n",
    "    \"Vol. S.A.\",\n",
    "    \"Grav. S.A.\",\n",
    "    \"Pore diameter Limiting\",\n",
    "    \"Pore diameter Largest\",\n",
    "]\n",
    "one_filter_columns = [\"H2@100 bar/243K (wt%)\"]\n",
    "another_filter_columns = [\"H2@100 bar/130K (wt%)\"]\n",
    "\n",
    "# load data\n",
    "data = data_loader(base_path, file_name)\n",
    "\n",
    "# extract descriptors and gas adsorptions\n",
    "one_property = one_filter(data, one_filter_columns)\n",
    "descriptors = get_descriptors(data, descriptor_columns)\n",
    "\n",
    "# prepare training inputs and outputs\n",
    "X = np.array(descriptors.values, dtype=np.float32)\n",
    "y = np.array(one_property.values, dtype=np.float32).reshape(len(X),)\n",
    "X = data_scaler(X)\n",
    "y = data_scaler(y.reshape(-1, 1)).reshape(len(X),)\n",
    "\n",
    "# makes transfer trials... more of a legacy code ---- function cannot be pulled out of .py bc of data dependencies\n",
    "def transfer_learning(\n",
    "    s_param, learning_rate, transfer=False, nsamples=None, names=None,s_run=True\n",
    "):\n",
    "    Ns = list()\n",
    "    scores_test = list()\n",
    "    scores_train = list()\n",
    "    seed=1\n",
    "    X_train,X_test,y_train,y_test=stratified_cluster_sample(seed,data,descriptor_columns,one_filter_columns[0],5)\n",
    "    X_train=X_train.drop([\"H2@100 bar/243K (wt%)\",\"Cluster\"],axis=1)\n",
    "    X_test=X_test.drop([\"H2@100 bar/243K (wt%)\",\"Cluster\"],axis=1)\n",
    "    X_train=np.array(X_train).astype(\"float32\")\n",
    "    X_test=np.array(X_test).astype(\"float32\")\n",
    "    y_train=np.array(y_train).astype(\"float32\")\n",
    "    y_test=np.array(y_test).astype(\"float32\")\n",
    "    ## model, loss, and optimizer\n",
    "    if transfer:\n",
    "        model = NeuralNet_sherpa_optimize(5,1,s_param).to(device)\n",
    "        model.load_state_dict(torch.load(\"temp_model.ckpt\"))\n",
    "        model.fc1.weight.requires_grad = False\n",
    "        model.fc1.bias.requires_grad = False\n",
    "        model.fc2.weight.requires_grad = False\n",
    "        model.fc2.bias.requires_grad = False\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate\n",
    "        )\n",
    "    else:\n",
    "        model = NeuralNet_sherpa_optimize(5,1,s_param).to(device)\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    ## train, val, test data split\n",
    "    #no val split for now \n",
    "\n",
    "    scores_epoch = list()\n",
    "    num_epochs = 5000\n",
    "    N = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        inputs = torch.from_numpy(X_train)\n",
    "        labels = torch.from_numpy(y_train)\n",
    "\n",
    "        outputs = model(inputs).view(-1,)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        N += 1\n",
    "        if epoch % 500 == 0:\n",
    "            inputs_val = torch.from_numpy(X_val)\n",
    "            labels_val = torch.from_numpy(y_val)\n",
    "\n",
    "            outputs_val = model(inputs_val).view(-1,)\n",
    "            score_train = r2_score(\n",
    "            torch.from_numpy(y_train).data.numpy(),\n",
    "            model(torch.from_numpy(X_train)).view(-1,).data.numpy(),\n",
    "            )\n",
    "            score = r2_score(labels_val.data.numpy(), outputs_val.data.numpy())\n",
    "            study.add_observation(\n",
    "                trial=trial,\n",
    "                iteration=epoch,\n",
    "                objective=score,\n",
    "                context={\"training_error\": score_train},\n",
    "            )\n",
    "            #         print('Predictive accuracy on validation set at epoch {}/{} is {}'.format(epoch, num_epochs, score))\n",
    "            scores_epoch.append(score)\n",
    "        \"\"\"\n",
    "        if len(scores_epoch) >= 2:\n",
    "            if score < scores_epoch[-2]:\n",
    "                break\n",
    "        \"\"\"\n",
    "        #scores_epochs.append(scores_epoch)\n",
    "        Ns.append(N)\n",
    "\n",
    "        score_train = r2_score(\n",
    "            torch.from_numpy(y_train).data.numpy(),\n",
    "            model(torch.from_numpy(X_train)).view(-1,).data.numpy(),\n",
    "        )\n",
    "        #         score_train = mean_squared_error(torch.from_numpy(y_train).data.numpy(), model(torch.from_numpy(X_train)).view(-1,).data.numpy())\n",
    "        scores_train.append(score_train)\n",
    "\n",
    "        #pred_tests.append(model(torch.from_numpy(X_test)).view(-1,).data.numpy())\n",
    "        #grt_train_X.append(torch.from_numpy(X_train).data.numpy())\n",
    "        #grt_test_X.append(torch.from_numpy(X_test).data.numpy())\n",
    "        #grt_tests.append(torch.from_numpy(y_test).data.numpy())\n",
    "        score_test = r2_score(\n",
    "            torch.from_numpy(y_test).data.numpy(),\n",
    "            model(torch.from_numpy(X_test)).view(-1,).data.numpy(),\n",
    "        )\n",
    "        #         score_test = mean_squared_error(torch.from_numpy(y_test).data.numpy(), model(torch.from_numpy(X_test)).view(-1,).data.numpy())\n",
    "        scores_test.append(score_test)\n",
    "    if s_run:\n",
    "        study.add_observation(\n",
    "            trial=trial,\n",
    "            iteration=N,\n",
    "            objective=score,\n",
    "            context={\"training_error\": score_train},\n",
    "        )\n",
    "        study.finalize(trial)\n",
    "        return\n",
    "    else:\n",
    "        return scores_train, scores_test\n",
    "\n",
    "\n",
    "for trial in study:\n",
    "    learning_rate = trial.parameters[\"lr\"]\n",
    "    # batch=trial.parameters[\"Epoch\"]\n",
    "    ## model, loss, and optimizer\n",
    "    # always used 5 features to make 1 prediction hence 5,1\n",
    "    model = NeuralNet_sherpa_optimize(5, 1, trial.parameters).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    ## train, val, test data split\n",
    "    # note these are not split by cluster yet.....\n",
    "    seed=1\n",
    "    cluster=5\n",
    "    len(data)\n",
    "    X_train,X_test,y_train,y_test=stratified_cluster_sample(seed,data,descriptor_columns,one_filter_columns[0],5,sample=int(len(data)*.9*.8)+1)\n",
    "    # Training\n",
    "    scores_epochs = list()\n",
    "    num_epochs = 50\n",
    "    z=y_train\n",
    "    X_train=X_train.drop([\"H2@100 bar/243K (wt%)\",\"Cluster\"],axis=1)\n",
    "    X_test=X_test.drop([\"H2@100 bar/243K (wt%)\",\"Cluster\"],axis=1)\n",
    "    X_train=np.array(X_train).astype(\"float32\")\n",
    "    X_test=np.array(X_test).astype(\"float32\")\n",
    "    y_train=np.array(y_train).astype(\"float32\")\n",
    "    y_test=np.array(y_test).astype(\"float32\")\n",
    "    print(y_test)\n",
    "    for epoch in range(num_epochs):\n",
    "        inputs = torch.from_numpy(X_train)\n",
    "        labels = torch.from_numpy(y_train)\n",
    "\n",
    "        outputs = model(inputs).view(-1,)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss)\n",
    "    score_test = r2_score(\n",
    "        torch.from_numpy(y_test).data.numpy(),\n",
    "        model(torch.from_numpy(X_test)).view(-1,).data.numpy(),\n",
    "    )\n",
    "    score_train = r2_score(\n",
    "        torch.from_numpy(y_train).data.numpy(),\n",
    "        model(torch.from_numpy(X_train)).view(-1,).data.numpy(),\n",
    "    )\n",
    "    print(score_test,score_train)\n",
    "    #torch.save(model.state_dict(), \"temp_model.ckpt\")\n",
    "    #transfer_learning(trial.parameters,learning_rate,transfer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'H2@100 bar/100 (wt%)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'H2@100 bar/100 (wt%)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12660/1041631317.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'H2@100 bar/100 (wt%)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'H2@100 bar/100 (wt%)'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11000/2204163479.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gcooper2\\Documents\\GitHub\\TL_MOF\\transfer_learning.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sherpa\n",
    "\n",
    "# help function\n",
    "from transfer_learning import NeuralNet_sherpa_optimize\n",
    "from dataset_loader import (\n",
    "    data_loader,\n",
    "    all_filter,\n",
    "    get_descriptors,\n",
    "    one_filter,\n",
    "    data_scaler,\n",
    ")\n",
    "\n",
    "# modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from Statistics_helper import stratified_cluster_sample\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "parameters = [\n",
    "    sherpa.Continuous(name=\"lr\", range=[0.0002, 0.1], scale=\"log\"),\n",
    "    # sherpa.Discrete(name='Epoch', range=[10,100]),\n",
    "    sherpa.Discrete(name=\"H_l1\", range=[10, 300]),\n",
    "    sherpa.Choice(\n",
    "        name=\"activate\",\n",
    "        range=[\"nn.Hardswish\", \"nn.PReLU\", \"nn.ReLU\", \"nn.Sigmoid\", \"nn.LeakyReLU\"],\n",
    "    ),\n",
    "]\n",
    "algorithm = sherpa.algorithms.RandomSearch(max_num_trials=10)\n",
    "study = sherpa.Study(\n",
    "    parameters=parameters,\n",
    "    algorithm=algorithm,\n",
    "    lower_is_better=False,\n",
    "    disable_dashboard=True,\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_path = os.getcwd()\n",
    "file_name = \"data/CrystGrowthDesign_SI.csv\"\n",
    "\n",
    "\"\"\"\n",
    "Data description.\n",
    "    Descriptors:\n",
    "        'void fraction', 'Vol. S.A.', 'Grav. S.A.', 'Pore diameter Limiting', 'Pore diameter Largest'\n",
    "    Source task:\n",
    "        'H2@100 bar/243K (wt%)'\n",
    "    Target tasks:\n",
    "        'H2@100 bar/130K (wt%)' 'CH4@100 bar/298 K (mg/g)' '5 bar Xe mol/kg' '5 bar Kr mol/kg'\n",
    "\"\"\"\n",
    "\n",
    "descriptor_columns = [\n",
    "    \"void fraction\",\n",
    "    \"Vol. S.A.\",\n",
    "    \"Grav. S.A.\",\n",
    "    \"Pore diameter Limiting\",\n",
    "    \"Pore diameter Largest\",\n",
    "]\n",
    "one_filter_columns = [\"H2@100 bar/243K (wt%)\"]\n",
    "another_filter_columns = [\"H2@100 bar/130K (wt%)\"]\n",
    "\n",
    "# load data\n",
    "data = data_loader(base_path, file_name)\n",
    "\n",
    "# extract descriptors and gas adsorptions\n",
    "one_property = one_filter(data, one_filter_columns)\n",
    "descriptors = get_descriptors(data, descriptor_columns)\n",
    "\n",
    "# prepare training inputs and outputs\n",
    "X = np.array(descriptors.values, dtype=np.float32)\n",
    "y = np.array(one_property.values, dtype=np.float32).reshape(len(X),)\n",
    "X = data_scaler(X)\n",
    "y = data_scaler(y.reshape(-1, 1)).reshape(len(X),)\n",
    "\n",
    "# makes transfer trials... more of a legacy code ---- function cannot be pulled out of .py bc of data dependencies\n",
    "def transfer_learning(\n",
    "    s_param, learning_rate, transfer=False, nsamples=None, nbatches=None, names=None\n",
    "):\n",
    "    seeds = np.arange(nbatches)\n",
    "    Ns = list()\n",
    "    scores_epochs = list()\n",
    "    scores_test = list()\n",
    "    scores_train = list()\n",
    "\n",
    "    pred_tests = list()\n",
    "    grt_train_X = list()\n",
    "    grt_test_X = list()\n",
    "    grt_tests = list()\n",
    "\n",
    "    for seed in seeds:\n",
    "        X_train,X_test,y_train,y_test=stratified_cluster_sample(data,descriptor_columns,one_filter_columns[0],5)\n",
    "\n",
    "        ## model, loss, and optimizer\n",
    "        if transfer:\n",
    "            model = NeuralNet_sherpa_optimize(5,1,s_param).to(device)\n",
    "            model.load_state_dict(torch.load(\"temp_model.ckpt\"))\n",
    "            model.fc1.weight.requires_grad = False\n",
    "            model.fc1.bias.requires_grad = False\n",
    "            model.fc2.weight.requires_grad = False\n",
    "            model.fc2.bias.requires_grad = False\n",
    "\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(\n",
    "                filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate\n",
    "            )\n",
    "        else:\n",
    "            model = NeuralNet_sherpa_optimize(5,1,s_param).to(device)\n",
    "\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        ## train, val, test data split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_small, y_small, test_size=0.1, random_state=1\n",
    "        )\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train, y_train, test_size=0.2, random_state=1\n",
    "        )\n",
    "\n",
    "        scores_epoch = list()\n",
    "        num_epochs = 5000\n",
    "        N = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            inputs = torch.from_numpy(X_train)\n",
    "            labels = torch.from_numpy(y_train)\n",
    "\n",
    "            outputs = model(inputs).view(-1,)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            N += 1\n",
    "            if epoch % 5 == 0:\n",
    "                inputs_val = torch.from_numpy(X_val)\n",
    "                labels_val = torch.from_numpy(y_val)\n",
    "\n",
    "                outputs_val = model(inputs_val).view(-1,)\n",
    "                score = r2_score(labels_val.data.numpy(), outputs_val.data.numpy())\n",
    "                #         print('Predictive accuracy on validation set at epoch {}/{} is {}'.format(epoch, num_epochs, score))\n",
    "                scores_epoch.append(score)\n",
    "            if len(scores_epoch) >= 2:\n",
    "                if score < scores_epoch[-2]:\n",
    "                    break\n",
    "        scores_epochs.append(scores_epoch)\n",
    "        Ns.append(N)\n",
    "\n",
    "        score_train = r2_score(\n",
    "            torch.from_numpy(y_train).data.numpy(),\n",
    "            model(torch.from_numpy(X_train)).view(-1,).data.numpy(),\n",
    "        )\n",
    "        #         score_train = mean_squared_error(torch.from_numpy(y_train).data.numpy(), model(torch.from_numpy(X_train)).view(-1,).data.numpy())\n",
    "        scores_train.append(score_train)\n",
    "\n",
    "        pred_tests.append(model(torch.from_numpy(X_test)).view(-1,).data.numpy())\n",
    "        grt_train_X.append(torch.from_numpy(X_train).data.numpy())\n",
    "        grt_test_X.append(torch.from_numpy(X_test).data.numpy())\n",
    "        grt_tests.append(torch.from_numpy(y_test).data.numpy())\n",
    "        score_test = r2_score(\n",
    "            torch.from_numpy(y_test).data.numpy(),\n",
    "            model(torch.from_numpy(X_test)).view(-1,).data.numpy(),\n",
    "        )\n",
    "        #         score_test = mean_squared_error(torch.from_numpy(y_test).data.numpy(), model(torch.from_numpy(X_test)).view(-1,).data.numpy())\n",
    "        scores_test.append(score_test)\n",
    "        torch.save(model, f\"{name}.pt\")\n",
    "\n",
    "    return scores_train, scores_test, grt_train_X, grt_test_X\n",
    "\n",
    "\n",
    "for trial in study:\n",
    "    learning_rate = trial.parameters[\"lr\"]\n",
    "    # batch=trial.parameters[\"Epoch\"]\n",
    "    ## model, loss, and optimizer\n",
    "    # always used 5 features to make 1 prediction hence 5,1\n",
    "    model = NeuralNet_sherpa_optimize(5, 1, trial.parameters).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    ## train, val, test data split\n",
    "    # note these are not split by cluster yet.....\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.1, random_state=1\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=1\n",
    "    )\n",
    "\n",
    "    # Training\n",
    "    scores_epochs = list()\n",
    "    num_epochs = 5000\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        inputs = torch.from_numpy(X_train)\n",
    "        labels = torch.from_numpy(y_train)\n",
    "\n",
    "        outputs = model(inputs).view(-1,)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 500 == 0:\n",
    "            inputs_val = torch.from_numpy(X_val)\n",
    "            labels_val = torch.from_numpy(y_val)\n",
    "\n",
    "            outputs_val = model(inputs_val).view(-1,)\n",
    "            score = r2_score(labels_val.data.numpy(), outputs_val.data.numpy())\n",
    "            score_train = r2_score(\n",
    "                torch.from_numpy(y_train).data.numpy(),\n",
    "                model(torch.from_numpy(X_train)).view(-1,).data.numpy(),\n",
    "            )\n",
    "            study.add_observation(\n",
    "                trial=trial,\n",
    "                iteration=epoch,\n",
    "                objective=score,\n",
    "                context={\"training_error\": score_train},\n",
    "            )\n",
    "\n",
    "    #         print('Predictive accuracy on validation set at epoch {}/{} is {}'.format(epoch, num_epochs, score))\n",
    "    score_test = r2_score(\n",
    "        torch.from_numpy(y_test).data.numpy(),\n",
    "        model(torch.from_numpy(X_test)).view(-1,).data.numpy(),\n",
    "    )\n",
    "    score_train = r2_score(\n",
    "        torch.from_numpy(y_train).data.numpy(),\n",
    "        model(torch.from_numpy(X_train)).view(-1,).data.numpy(),\n",
    "    )\n",
    "    torch.save(model.state_dict(), \"temp_model.ckpt\")\n",
    "    study.add_observation(\n",
    "        trial=trial, objective=score_test, context={\"training_error\": score_train}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.1, random_state=1\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.41236869,  1.3647112 , -0.9929197 , -0.8678267 , -1.1067593 ],\n",
       "       [-1.0701612 ,  1.6423824 , -0.79077667, -1.2354654 , -1.2005417 ],\n",
       "       [-0.98793733,  1.4928671 , -0.8954323 , -1.1694789 , -1.1849114 ],\n",
       "       ...,\n",
       "       [ 0.16319996,  0.43771687, -0.01231059, -0.73585385, -0.11422778],\n",
       "       [ 0.65654457, -0.63024896,  0.8521738 ,  1.0552063 ,  1.1440207 ],\n",
       "       [ 0.57432055, -0.55335546,  0.63856155, -0.08541627,  0.6360321 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd5732a15d3d8c897dbd8ffbef8bd31e71c34b3f7fdf04b13db074e3049d3f0c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
