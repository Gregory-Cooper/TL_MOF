{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregcooper/Desktop/Research/TL_MOF/Statistics_helper.py:136: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_train=X_train.append(X_train_1)\n",
      "/Users/gregcooper/Desktop/Research/TL_MOF/Statistics_helper.py:137: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_test=X_test.append(X_test_1)\n",
      "/Users/gregcooper/Desktop/Research/TL_MOF/Statistics_helper.py:136: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_train=X_train.append(X_train_1)\n",
      "/Users/gregcooper/Desktop/Research/TL_MOF/Statistics_helper.py:137: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_test=X_test.append(X_test_1)\n",
      "/Users/gregcooper/Desktop/Research/TL_MOF/Statistics_helper.py:136: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_train=X_train.append(X_train_1)\n",
      "/Users/gregcooper/Desktop/Research/TL_MOF/Statistics_helper.py:137: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_test=X_test.append(X_test_1)\n",
      "/Users/gregcooper/Desktop/Research/TL_MOF/Statistics_helper.py:136: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_train=X_train.append(X_train_1)\n",
      "/Users/gregcooper/Desktop/Research/TL_MOF/Statistics_helper.py:137: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_test=X_test.append(X_test_1)\n",
      "/Users/gregcooper/Desktop/Research/TL_MOF/Statistics_helper.py:136: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_train=X_train.append(X_train_1)\n",
      "/Users/gregcooper/Desktop/Research/TL_MOF/Statistics_helper.py:137: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_test=X_test.append(X_test_1)\n"
     ]
    }
   ],
   "source": [
    "# help function\n",
    "from transfer_learning import NeuralNet\n",
    "from dataset_loader import data_loader, get_descriptors, one_filter, data_scaler\n",
    "\n",
    "# modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# New\n",
    "from transfer_learning import MyDataset\n",
    "from Statistics_helper import stratified_cluster_sample\n",
    "from ignite.engine import Engine, Events, create_supervised_evaluator\n",
    "from ignite.metrics import Loss\n",
    "from ignite.contrib.metrics.regression import R2Score\n",
    "import time\n",
    "from ignite.engine import Events, create_supervised_evaluator\n",
    "\n",
    "# file name and data path\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_path = os.getcwd()\n",
    "file_name = \"data/CrystGrowthDesign_SI.csv\"\n",
    "\n",
    "\"\"\"\n",
    "Data description.\n",
    "\n",
    "    Descriptors:\n",
    "        'void fraction', 'Vol. S.A.', 'Grav. S.A.', 'Pore diameter Limiting', 'Pore diameter Largest'\n",
    "    Source task:\n",
    "        'H2@100 bar/243K (wt%)'\n",
    "    Target tasks:\n",
    "        'H2@100 bar/130K (wt%)' 'CH4@100 bar/298 K (mg/g)' '5 bar Xe mol/kg' '5 bar Kr mol/kg'\n",
    "\"\"\"\n",
    "\n",
    "descriptor_columns = [\n",
    "    \"void fraction\",\n",
    "    \"Vol. S.A.\",\n",
    "    \"Grav. S.A.\",\n",
    "    \"Pore diameter Limiting\",\n",
    "    \"Pore diameter Largest\",\n",
    "]\n",
    "one_filter_columns = [\"H2@100 bar/243K (wt%)\"]\n",
    "another_filter_columns = [\"H2@100 bar/130K (wt%)\"]\n",
    "\n",
    "# load data\n",
    "data = data_loader(base_path, file_name)\n",
    "data = data.reset_index(drop=True)\n",
    "# parameters\n",
    "input_size = 6\n",
    "hidden_size_1 = 128\n",
    "hidden_size_2 = 64\n",
    "output_size = 1\n",
    "learning_rate = 0.0002\n",
    "\n",
    "# file specifics \n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "filename = f\"data_epochs-{epochs}_bs-{batch_size}\"\n",
    "\n",
    "#format data\n",
    "df, t_1, t_2, y_1, y_2 = stratified_cluster_sample(\n",
    "    1, data, descriptor_columns, another_filter_columns[0], 5, net_out=True\n",
    ")\n",
    "df = df[0]\n",
    "# df=df.drop(\"Cluster\",axis=1)\n",
    "interest = another_filter_columns[0]\n",
    "descriptor_columns.append(\"Cluster\")\n",
    "features = descriptor_columns\n",
    "\n",
    "df_train, df_val, y_df_train, y_df_val = train_test_split(\n",
    "    df[features], df[interest], test_size=0.1\n",
    ")\n",
    "df_train[interest] = np.array(y_df_train)\n",
    "df_val[interest] = np.array(y_df_val)\n",
    "first = MyDataset(df_train, interest, features)\n",
    "train_loader = torch.utils.data.DataLoader(first, batch_size=512)\n",
    "second = MyDataset(df_val, interest, features)\n",
    "val_loader = torch.utils.data.DataLoader(second, batch_size=len(df_val))\n",
    "\n",
    "train_loss = []\n",
    "train_r_2 = []\n",
    "val_loss = []\n",
    "val_r_2 = []\n",
    "net_time = []\n",
    "#create model\n",
    "model = NeuralNet(input_size, hidden_size_1, hidden_size_2, output_size).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "def train_step(engine, batch):\n",
    "    x, y = batch\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "trainer = Engine(train_step)\n",
    "# trainer.logger = setup_logger(\"Trainer\")\n",
    "@trainer.on(Events.EPOCH_COMPLETED(every=10))\n",
    "def log_training(engine):\n",
    "    batch_loss = engine.state.output\n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "    e = engine.state.epoch\n",
    "    n = engine.state.max_epochs\n",
    "    i = engine.state.iteration\n",
    "    # print(f\"Epoch {e}/{n} : {i} - batch loss: {batch_loss}, lr: {lr}\")\n",
    "\n",
    "\n",
    "metrics = {\"loss\": Loss(criterion), \"r_2\": R2Score()}\n",
    "\n",
    "train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "# train_evaluator.logger = setup_logger(\"Train Evaluator\")\n",
    "validation_evaluator = create_supervised_evaluator(\n",
    "    model, metrics=metrics, device=device\n",
    ")\n",
    "# validation_evaluator.logger = setup_logger(\"Val Evaluator\")\n",
    "\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def store_metrics(engine):\n",
    "    train_evaluator.run(train_loader)\n",
    "    validation_evaluator.run(val_loader)\n",
    "    out = train_evaluator.state.metrics\n",
    "    out_2 = validation_evaluator.state.metrics\n",
    "    end = time.time()\n",
    "    train_loss.append(out[\"loss\"])\n",
    "    train_r_2.append(out[\"r_2\"])\n",
    "    val_loss.append(out_2[\"loss\"])\n",
    "    val_r_2.append(out_2[\"r_2\"])\n",
    "    net_time.append(end-start)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(first, batch_size=batch_size,shuffle=True)\n",
    "start = time.time()\n",
    "trainer.run(train_loader, max_epochs=epochs)\n",
    "\n",
    "dic = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_r_2\": train_r_2,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_r_2\": val_r_2,\n",
    "    \"net_time\" : net_time,\n",
    "}\n",
    "case_metrics = pd.DataFrame.from_dict(dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_r_2</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_r_2</th>\n",
       "      <th>net_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.362988</td>\n",
       "      <td>-1.598243</td>\n",
       "      <td>88.890642</td>\n",
       "      <td>-1.609449</td>\n",
       "      <td>0.210954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.153936</td>\n",
       "      <td>0.183071</td>\n",
       "      <td>27.441875</td>\n",
       "      <td>0.194424</td>\n",
       "      <td>0.410905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.070511</td>\n",
       "      <td>0.757198</td>\n",
       "      <td>8.217582</td>\n",
       "      <td>0.758767</td>\n",
       "      <td>0.604318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.090409</td>\n",
       "      <td>0.907025</td>\n",
       "      <td>3.319059</td>\n",
       "      <td>0.902567</td>\n",
       "      <td>0.795139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.043479</td>\n",
       "      <td>0.938522</td>\n",
       "      <td>2.243799</td>\n",
       "      <td>0.934132</td>\n",
       "      <td>0.987339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.650713</td>\n",
       "      <td>0.950338</td>\n",
       "      <td>1.806259</td>\n",
       "      <td>0.946976</td>\n",
       "      <td>1.200243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.424750</td>\n",
       "      <td>0.957136</td>\n",
       "      <td>1.541800</td>\n",
       "      <td>0.954739</td>\n",
       "      <td>1.417789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.248748</td>\n",
       "      <td>0.962431</td>\n",
       "      <td>1.335107</td>\n",
       "      <td>0.960807</td>\n",
       "      <td>1.638375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.110198</td>\n",
       "      <td>0.966600</td>\n",
       "      <td>1.174078</td>\n",
       "      <td>0.965534</td>\n",
       "      <td>1.855785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.997480</td>\n",
       "      <td>0.969991</td>\n",
       "      <td>1.043808</td>\n",
       "      <td>0.969358</td>\n",
       "      <td>2.066551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_r_2   val_loss   val_r_2  net_time\n",
       "0   86.362988  -1.598243  88.890642 -1.609449  0.210954\n",
       "1   27.153936   0.183071  27.441875  0.194424  0.410905\n",
       "2    8.070511   0.757198   8.217582  0.758767  0.604318\n",
       "3    3.090409   0.907025   3.319059  0.902567  0.795139\n",
       "4    2.043479   0.938522   2.243799  0.934132  0.987339\n",
       "5    1.650713   0.950338   1.806259  0.946976  1.200243\n",
       "6    1.424750   0.957136   1.541800  0.954739  1.417789\n",
       "7    1.248748   0.962431   1.335107  0.960807  1.638375\n",
       "8    1.110198   0.966600   1.174078  0.965534  1.855785\n",
       "9    0.997480   0.969991   1.043808  0.969358  2.066551"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08e68b6ed4c3e6ab7f2854c6050494f7e80cd03b8cabcf5e57c6479ed706d2af"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('Transfer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
