{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help function\n",
    "from transfer_learning import NeuralNet\n",
    "from dataset_loader import data_loader, get_descriptors, one_filter, data_scaler\n",
    "\n",
    "# modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# New\n",
    "from transfer_learning import MyDataset\n",
    "from Statistics_helper import stratified_cluster_sample\n",
    "from ignite.engine import Engine, Events, create_supervised_evaluator\n",
    "from ignite.metrics import Loss\n",
    "from ignite.contrib.metrics.regression import R2Score\n",
    "import time\n",
    "from ignite.engine import Events, create_supervised_evaluator\n",
    "\n",
    "# file name and data path\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_path = os.getcwd()\n",
    "file_name = \"data/CrystGrowthDesign_SI.csv\"\n",
    "\n",
    "\"\"\"\n",
    "Data description.\n",
    "\n",
    "    Descriptors:\n",
    "        'void fraction', 'Vol. S.A.', 'Grav. S.A.', 'Pore diameter Limiting', 'Pore diameter Largest'\n",
    "    Source task:\n",
    "        'H2@100 bar/243K (wt%)'\n",
    "    Target tasks:\n",
    "        'H2@100 bar/130K (wt%)' 'CH4@100 bar/298 K (mg/g)' '5 bar Xe mol/kg' '5 bar Kr mol/kg'\n",
    "\"\"\"\n",
    "\n",
    "descriptor_columns = [\n",
    "    \"void fraction\",\n",
    "    \"Vol. S.A.\",\n",
    "    \"Grav. S.A.\",\n",
    "    \"Pore diameter Limiting\",\n",
    "    \"Pore diameter Largest\",\n",
    "]\n",
    "one_filter_columns = [\"H2@100 bar/243K (wt%)\"]\n",
    "another_filter_columns = [\"H2@100 bar/130K (wt%)\"]\n",
    "\n",
    "# load data\n",
    "data = data_loader(base_path, file_name)\n",
    "data = data.reset_index(drop=True)\n",
    "# parameters\n",
    "input_size = 6\n",
    "hidden_size_1 = 128\n",
    "hidden_size_2 = 64\n",
    "output_size = 1\n",
    "learning_rate = 0.0002\n",
    "\n",
    "# file specifics \n",
    "epochs = 100\n",
    "batch_size = 128\n",
    "filename = f\"data_epochs-{epochs}_bs-{batch_size}\"\n",
    "\n",
    "#format data\n",
    "df, t_1, t_2, y_1, y_2 = stratified_cluster_sample(\n",
    "    1, data, descriptor_columns, one_filter_columns[0], 5, net_out=True\n",
    ")\n",
    "df = df[0]\n",
    "# df=df.drop(\"Cluster\",axis=1)\n",
    "interest = one_filter_columns[0]\n",
    "descriptor_columns.append(\"Cluster\")\n",
    "features = descriptor_columns\n",
    "\n",
    "df_train, df_val, y_df_train, y_df_val = train_test_split(\n",
    "    df[features], df[interest], test_size=0.1\n",
    ")\n",
    "df_train[interest] = np.array(y_df_train)\n",
    "df_val[interest] = np.array(y_df_val)\n",
    "first = MyDataset(df_train, interest, features)\n",
    "train_loader = torch.utils.data.DataLoader(first, batch_size=batch_size)\n",
    "second = MyDataset(df_val, interest, features)\n",
    "val_loader = torch.utils.data.DataLoader(second, batch_size=len(df_val))\n",
    "\n",
    "train_loss = []\n",
    "train_r_2 = []\n",
    "val_loss = []\n",
    "val_r_2 = []\n",
    "net_time = []\n",
    "#create model\n",
    "model = NeuralNet(input_size, hidden_size_1, hidden_size_2, output_size).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "def train_step(engine, batch):\n",
    "    x, y = batch\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "trainer = Engine(train_step)\n",
    "# trainer.logger = setup_logger(\"Trainer\")\n",
    "@trainer.on(Events.EPOCH_COMPLETED(every=10))\n",
    "def log_training(engine):\n",
    "    batch_loss = engine.state.output\n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "    e = engine.state.epoch\n",
    "    n = engine.state.max_epochs\n",
    "    i = engine.state.iteration\n",
    "    # print(f\"Epoch {e}/{n} : {i} - batch loss: {batch_loss}, lr: {lr}\")\n",
    "\n",
    "\n",
    "metrics = {\"loss\": Loss(criterion), \"r_2\": R2Score()}\n",
    "\n",
    "train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "# train_evaluator.logger = setup_logger(\"Train Evaluator\")\n",
    "validation_evaluator = create_supervised_evaluator(\n",
    "    model, metrics=metrics, device=device\n",
    ")\n",
    "# validation_evaluator.logger = setup_logger(\"Val Evaluator\")\n",
    "\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def store_metrics(engine):\n",
    "    train_evaluator.run(train_loader)\n",
    "    validation_evaluator.run(val_loader)\n",
    "    out = train_evaluator.state.metrics\n",
    "    out_2 = validation_evaluator.state.metrics\n",
    "    end = time.time()\n",
    "    train_loss.append(out[\"loss\"])\n",
    "    train_r_2.append(out[\"r_2\"])\n",
    "    val_loss.append(out_2[\"loss\"])\n",
    "    val_r_2.append(out_2[\"r_2\"])\n",
    "    net_time.append(end-start)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(first, batch_size=batch_size,shuffle=True)\n",
    "start = time.time()\n",
    "trainer.run(train_loader, max_epochs=epochs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "descriptor_columns = [\n",
    "    \"void fraction\",\n",
    "    \"Vol. S.A.\",\n",
    "    \"Grav. S.A.\",\n",
    "    \"Pore diameter Limiting\",\n",
    "    \"Pore diameter Largest\",\n",
    "]\n",
    "model.fc1.weight.requires_grad = False\n",
    "model.fc1.bias.requires_grad = False\n",
    "model.fc2.weight.requires_grad = False\n",
    "model.fc2.bias.requires_grad = False\n",
    "optimizer = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate\n",
    ")\n",
    "df, t_1, t_2, y_1, y_2 = stratified_cluster_sample(\n",
    "    1, data, descriptor_columns, another_filter_columns[0], 5, net_out=True\n",
    ")\n",
    "df = df[0]\n",
    "# df=df.drop(\"Cluster\",axis=1)\n",
    "interest = another_filter_columns[0]\n",
    "descriptor_columns.append(\"Cluster\")\n",
    "features = descriptor_columns\n",
    "\n",
    "df_train, df_val, y_df_train, y_df_val = train_test_split(\n",
    "    df[features], df[interest], test_size=0.1\n",
    ")\n",
    "df_train[interest] = np.array(y_df_train)\n",
    "df_val[interest] = np.array(y_df_val)\n",
    "first = MyDataset(df_train, interest, features)\n",
    "train_loader = torch.utils.data.DataLoader(first, batch_size=batch_size)\n",
    "second = MyDataset(df_val, interest, features)\n",
    "val_loader = torch.utils.data.DataLoader(second, batch_size=len(df_val))\n",
    "\n",
    "interest=another_filter_columns[0]\n",
    "first = MyDataset(df_train, interest, features)\n",
    "train_loader = torch.utils.data.DataLoader(first, batch_size=batch_size)\n",
    "second = MyDataset(df_val, interest, features)\n",
    "val_loader = torch.utils.data.DataLoader(second, batch_size=len(df_val))\n",
    "train_loss = []\n",
    "train_r_2 = []\n",
    "val_loss = []\n",
    "val_r_2 = []\n",
    "net_time = []\n",
    "trainer.run(train_loader, max_epochs=epochs)\n",
    "dic1 = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_r_2\": train_r_2,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_r_2\": val_r_2,\n",
    "    \"net_time\" : net_time,\n",
    "}\n",
    "case_metrics = pd.DataFrame.from_dict(dic1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_r_2</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_r_2</th>\n",
       "      <th>net_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.892570</td>\n",
       "      <td>0.285404</td>\n",
       "      <td>23.054709</td>\n",
       "      <td>0.286040</td>\n",
       "      <td>26.068841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.993729</td>\n",
       "      <td>0.551557</td>\n",
       "      <td>14.359634</td>\n",
       "      <td>0.555310</td>\n",
       "      <td>26.277292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.607209</td>\n",
       "      <td>0.712661</td>\n",
       "      <td>9.086801</td>\n",
       "      <td>0.718599</td>\n",
       "      <td>26.458807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.588046</td>\n",
       "      <td>0.802960</td>\n",
       "      <td>6.124258</td>\n",
       "      <td>0.810343</td>\n",
       "      <td>26.658273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.002897</td>\n",
       "      <td>0.850370</td>\n",
       "      <td>4.564933</td>\n",
       "      <td>0.858633</td>\n",
       "      <td>26.841782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.288714</td>\n",
       "      <td>0.991365</td>\n",
       "      <td>0.258935</td>\n",
       "      <td>0.991981</td>\n",
       "      <td>45.549812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.286897</td>\n",
       "      <td>0.991419</td>\n",
       "      <td>0.257280</td>\n",
       "      <td>0.992033</td>\n",
       "      <td>45.763245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.285131</td>\n",
       "      <td>0.991472</td>\n",
       "      <td>0.255671</td>\n",
       "      <td>0.992082</td>\n",
       "      <td>45.967698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.283416</td>\n",
       "      <td>0.991523</td>\n",
       "      <td>0.254107</td>\n",
       "      <td>0.992131</td>\n",
       "      <td>46.211047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.281750</td>\n",
       "      <td>0.991573</td>\n",
       "      <td>0.252586</td>\n",
       "      <td>0.992178</td>\n",
       "      <td>46.430460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_loss  train_r_2   val_loss   val_r_2   net_time\n",
       "0    23.892570   0.285404  23.054709  0.286040  26.068841\n",
       "1    14.993729   0.551557  14.359634  0.555310  26.277292\n",
       "2     9.607209   0.712661   9.086801  0.718599  26.458807\n",
       "3     6.588046   0.802960   6.124258  0.810343  26.658273\n",
       "4     5.002897   0.850370   4.564933  0.858633  26.841782\n",
       "..         ...        ...        ...       ...        ...\n",
       "95    0.288714   0.991365   0.258935  0.991981  45.549812\n",
       "96    0.286897   0.991419   0.257280  0.992033  45.763245\n",
       "97    0.285131   0.991472   0.255671  0.992082  45.967698\n",
       "98    0.283416   0.991523   0.254107  0.992131  46.211047\n",
       "99    0.281750   0.991573   0.252586  0.992178  46.430460\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_892/751394537.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gcooper2\\Documents\\GitHub\\TL_MOF\\transfer_learning.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not list"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08e68b6ed4c3e6ab7f2854c6050494f7e80cd03b8cabcf5e57c6479ed706d2af"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('Transfer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
