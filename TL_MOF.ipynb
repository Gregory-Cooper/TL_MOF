{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help function\n",
    "from transfer_learning import NeuralNet\n",
    "from dataset_loader import data_loader, all_filter, get_descriptors, one_filter, data_scaler\n",
    "\n",
    "# modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "# file name and data path\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "base_path = os.getcwd()\n",
    "file_name = 'data/CrystGrowthDesign_SI.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13506, 5)\n",
      "(13506,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Data description.\n",
    "\n",
    "    Descriptors:\n",
    "        'void fraction', 'Vol. S.A.', 'Grav. S.A.', 'Pore diameter Limiting', 'Pore diameter Largest'\n",
    "    Source task:\n",
    "        'H2@100 bar/243K (wt%)'\n",
    "    Target tasks:\n",
    "        'H2@100 bar/130K (wt%)' 'CH4@100 bar/298 K (mg/g)' '5 bar Xe mol/kg' '5 bar Kr mol/kg'\n",
    "\"\"\"\n",
    "\n",
    "descriptor_columns = ['void fraction', 'Vol. S.A.', 'Grav. S.A.', 'Pore diameter Limiting', 'Pore diameter Largest']\n",
    "one_filter_columns = ['H2@100 bar/243K (wt%)'] \n",
    "another_filter_columns = ['H2@100 bar/130K (wt%)'] \n",
    "\n",
    "# load data\n",
    "data = data_loader(base_path, file_name)\n",
    "\n",
    "# extract descriptors and gas adsorptions\n",
    "one_property = one_filter(data, another_filter_columns)\n",
    "descriptors = get_descriptors(data, descriptor_columns)\n",
    "\n",
    "# prepare training inputs and outputs\n",
    "X = np.array(descriptors.values, dtype=np.float32)\n",
    "y = np.array(one_property.values, dtype=np.float32).reshape(len(X), )\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "X = data_scaler(X)\n",
    "y = data_scaler(y.reshape(-1, 1)).reshape(len(X),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source task training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:50<00:00, 98.68it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Manuscript/H2_val.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m'\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[1;32m     47\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPre Acc on Val set\u001b[39m\u001b[38;5;124m'\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mManuscript/H2_val.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_inches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe predictive accuracy on test set is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     50\u001b[0m                 r2_score(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(y_test)\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy(), model(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(X_test))\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy())))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Transfer/lib/python3.9/site-packages/matplotlib/pyplot.py:958\u001b[0m, in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[38;5;241m.\u001b[39msavefig)\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msavefig\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    957\u001b[0m     fig \u001b[38;5;241m=\u001b[39m gcf()\n\u001b[0;32m--> 958\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m     fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw_idle()   \u001b[38;5;66;03m# need this if 'transparent=True' to reset colors\u001b[39;00m\n\u001b[1;32m    960\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Transfer/lib/python3.9/site-packages/matplotlib/figure.py:3019\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3015\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[1;32m   3016\u001b[0m         stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[1;32m   3017\u001b[0m             ax\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39m_cm_set(facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m-> 3019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Transfer/lib/python3.9/site-packages/matplotlib/backend_bases.py:2319\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2317\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2318\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[0;32m-> 2319\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2320\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2321\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2322\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2323\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2324\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2325\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Transfer/lib/python3.9/site-packages/matplotlib/backend_bases.py:1648\u001b[0m, in \u001b[0;36m_check_savefig_extra_args.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1640\u001b[0m     _api\u001b[38;5;241m.\u001b[39mwarn_deprecated(\n\u001b[1;32m   1641\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3.3\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39mname, removal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3.6\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1642\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m() got unexpected keyword argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1643\u001b[0m                 \u001b[38;5;241m+\u001b[39m arg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m which is no longer supported as of \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1644\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m and will become an error \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1645\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1646\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(arg)\n\u001b[0;32m-> 1648\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Transfer/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:412\u001b[0m, in \u001b[0;36mdelete_parameter.<locals>.wrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m     deprecation_addendum \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf any parameter follows \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m, they should be passed as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeyword, not positionally.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    405\u001b[0m     warn_deprecated(\n\u001b[1;32m    406\u001b[0m         since,\n\u001b[1;32m    407\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrepr\u001b[39m(name),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m                  \u001b[38;5;28;01melse\u001b[39;00m deprecation_addendum,\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minner_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minner_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Transfer/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:541\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;124;03mWrite the figure to a PNG file.\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;124;03m    *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    540\u001b[0m FigureCanvasAgg\u001b[38;5;241m.\u001b[39mdraw(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 541\u001b[0m \u001b[43mmpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Transfer/lib/python3.9/site-packages/matplotlib/image.py:1675\u001b[0m, in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m   1673\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m   1674\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, (dpi, dpi))\n\u001b[0;32m-> 1675\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Transfer/lib/python3.9/site-packages/PIL/Image.py:2209\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2207\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2208\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2209\u001b[0m         fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2211\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2212\u001b[0m     save_handler(\u001b[38;5;28mself\u001b[39m, fp, filename)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Manuscript/H2_val.png'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## hyper-parameters\n",
    "input_size = 5\n",
    "hidden_size_1 = 128\n",
    "hidden_size_2 = 64\n",
    "output_size = 1\n",
    "learning_rate = 0.00002\n",
    "\n",
    "## model, loss, and optimizer\n",
    "model = NeuralNet(input_size, hidden_size_1, hidden_size_2, output_size).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "## train, val, test data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "# Training\n",
    "scores_epochs = list()\n",
    "num_epochs = 5000\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    inputs = torch.from_numpy(X_train)\n",
    "    labels = torch.from_numpy(y_train)\n",
    "\n",
    "    outputs = model(inputs).view(-1,)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 5 == 0:\n",
    "        inputs_val = torch.from_numpy(X_val)\n",
    "        labels_val = torch.from_numpy(y_val)\n",
    "\n",
    "        outputs_val = model(inputs_val).view(-1,)\n",
    "        score = r2_score(labels_val.data.numpy(), outputs_val.data.numpy())\n",
    "#         print('Predictive accuracy on validation set at epoch {}/{} is {}'.format(epoch, num_epochs, score)) \n",
    "        scores_epochs.append(score)\n",
    "#     if len(scores_epochs) >= 2:\n",
    "#             if score < scores_epochs[-2]:\n",
    "#                 break\n",
    "\n",
    "# torch.save(model.state_dict(), 'model_H2.ckpt')  \n",
    "plt.plot(np.arange(0, num_epochs, 5), scores_epochs, color='red')\n",
    "plt.xlabel('Epochs', size=15)\n",
    "plt.ylabel('Pre Acc on Val set', size=15)\n",
    "plt.savefig('Manuscript/H2_val.png', bbox_inches='tight', dpi=500)\n",
    "print('The predictive accuracy on test set is {}'.format(\n",
    "                r2_score(torch.from_numpy(y_test).data.numpy(), model(torch.from_numpy(X_test)).view(-1,).data.numpy())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct learning and transfer learning on target tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_learning(transfer=False, nsamples=None, nbatches=None,name):\n",
    "    seeds = np.arange(nbatches)\n",
    "    Ns = list()\n",
    "    scores_epochs = list()\n",
    "    scores_test = list()\n",
    "    scores_train = list()\n",
    "\n",
    "    pred_tests = list()\n",
    "    grt_train_X = list()\n",
    "    grt_test_X = list()\n",
    "    grt_tests = list()\n",
    "\n",
    "    for seed in tqdm(seeds):\n",
    "        data_small = data.sample(n=nsamples, random_state=seed)\n",
    "\n",
    "        another_property = one_filter(data_small, another_filter_columns)\n",
    "        descriptors_small = get_descriptors(data_small, descriptor_columns)\n",
    "\n",
    "        X_small = np.array(descriptors_small.values, dtype=np.float32)\n",
    "        y_small = np.array(another_property.values, dtype=np.float32).reshape(len(X_small), )\n",
    "        \n",
    "        X_small = data_scaler(X_small)\n",
    "        y_small = data_scaler(y_small.reshape(-1, 1)).reshape(len(X_small),)\n",
    "\n",
    "        ## hyper-parameters\n",
    "        input_size = 5\n",
    "        hidden_size_1 = 128\n",
    "        hidden_size_2 = 64\n",
    "        output_size = 1\n",
    "        learning_rate = 0.00002\n",
    "\n",
    "        ## model, loss, and optimizer\n",
    "        if transfer:\n",
    "            model = NeuralNet(input_size, hidden_size_1, hidden_size_2, output_size).to(device)\n",
    "            model.load_state_dict(torch.load('model_H2.ckpt'))\n",
    "            model.fc1.weight.requires_grad = False\n",
    "            model.fc1.bias.requires_grad = False\n",
    "            model.fc2.weight.requires_grad = False\n",
    "            model.fc2.bias.requires_grad = False\n",
    "\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
    "        else:\n",
    "            model = NeuralNet(input_size, hidden_size_1, hidden_size_2, output_size).to(device)\n",
    "            \n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        ## train, val, test data split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_small, y_small, test_size=0.1, random_state=1)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "        scores_epoch = list()\n",
    "        num_epochs = 10000\n",
    "        N = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            inputs = torch.from_numpy(X_train)\n",
    "            labels = torch.from_numpy(y_train)\n",
    "\n",
    "            outputs = model(inputs).view(-1,)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            N += 1\n",
    "            if epoch % 5 == 0:\n",
    "                inputs_val = torch.from_numpy(X_val)\n",
    "                labels_val = torch.from_numpy(y_val)\n",
    "\n",
    "                outputs_val = model(inputs_val).view(-1,)\n",
    "                score = r2_score(labels_val.data.numpy(), outputs_val.data.numpy())\n",
    "        #         print('Predictive accuracy on validation set at epoch {}/{} is {}'.format(epoch, num_epochs, score)) \n",
    "                scores_epoch.append(score)\n",
    "            if len(scores_epoch) >= 2:\n",
    "                if score < scores_epoch[-2]:\n",
    "                    break\n",
    "        scores_epochs.append(scores_epoch)\n",
    "        Ns.append(N)\n",
    "    \n",
    "        score_train = r2_score(torch.from_numpy(y_train).data.numpy(), model(torch.from_numpy(X_train)).view(-1,).data.numpy())     \n",
    "#         score_train = mean_squared_error(torch.from_numpy(y_train).data.numpy(), model(torch.from_numpy(X_train)).view(-1,).data.numpy())     \n",
    "        scores_train.append(score_train)\n",
    "    \n",
    "        pred_tests.append(model(torch.from_numpy(X_test)).view(-1,).data.numpy())\n",
    "        grt_train_X.append(torch.from_numpy(X_train).data.numpy())\n",
    "        grt_test_X.append(torch.from_numpy(X_test).data.numpy())\n",
    "        grt_tests.append(torch.from_numpy(y_test).data.numpy())\n",
    "        score_test = r2_score(torch.from_numpy(y_test).data.numpy(), model(torch.from_numpy(X_test)).view(-1,).data.numpy())\n",
    "#         score_test = mean_squared_error(torch.from_numpy(y_test).data.numpy(), model(torch.from_numpy(X_test)).view(-1,).data.numpy())\n",
    "        scores_test.append(score_test)\n",
    "        torch.save(model, f'{name}.pt')\n",
    "    return scores_train, scores_test, grt_train_X, grt_test_X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:09:00<00:00,  4.14s/it]\n"
     ]
    }
   ],
   "source": [
    "scores_train_H2_130K_wo_transfer, scores_test_H2_130K_wo_transfer, grt_train_X_wo_transfer, grt_test_X_wo_transfer = transfer_learning(transfer=False, nsamples=100, nbatches=1000,\"One\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [35:26<00:00,  2.13s/it]\n"
     ]
    }
   ],
   "source": [
    "scores_train_H2_130K_w_transfer, scores_test_H2_130K_w_transfer, grt_train_X_w_transfer, grt_test_X_w_transfer = transfer_learning(transfer=True, nsamples=100, nbatches=1000,\"Two\")     \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
